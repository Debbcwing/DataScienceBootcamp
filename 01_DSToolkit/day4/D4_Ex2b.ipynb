{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79742c6b",
   "metadata": {},
   "source": [
    "## Custom Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a9853",
   "metadata": {},
   "source": [
    "You are free to scrape any website of your choice. The only constraint is that you should have fun while doing it! Pick an interesting site to scrape and analyze its content. Let us know what you find!\n",
    "\n",
    "1.1. Download all necessary information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ae02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6098441",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_kw = 'demise of chatgpt'\n",
    "search_kw_html = search_kw.replace(\" \", \"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scholar.google.com/scholar?start=10&q=demise+of+chatgpt&hl=en&as_sdt=0,5&as_rr=1\n",
    "# https://scholar.google.com/scholar?start=20&q=demise+of+chatgpt&hl=en&as_sdt=0,5&as_rr=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94233e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_df = pd.DataFrame(columns=['first_author', 'year', 'title', 'publisher', 'cited_by', 'link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefa1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61922c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try\n",
    "url = f\"https://scholar.google.com/scholar?start={0}&q=demise+of+chatgpt&hl=en&as_sdt=0,5&as_rr=1\"\n",
    "\n",
    "page = requests.get(url, headers=headers, timeout=2)    # order soup\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")       # cooking soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922bba05",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute \"get_text\". You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m job_ads \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# scoping soup\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mjob_ads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CDBootcamp/lib/python3.10/site-packages/bs4/element.py:2885\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2886\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   2887\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute \"get_text\". You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "job_ads = soup.find_all('a')  # scoping soup\n",
    "job_ads.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "max_pages = 500     # 500 pages; 10 items per page; 5000 nos of articles\n",
    "\n",
    "for p in range(1, max_pages+1): \n",
    "    page_no = str(p)\n",
    "    url = f\"https://scholar.google.com/scholar?start={p}&q=demise+of+chatgpt&hl=en&as_sdt=0,5&as_rr=1\"\n",
    "    time.sleep(2)   # put some break time\n",
    "    \n",
    "    page = requests.get(url, headers=headers, timeout=2)    # order soup\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")       # cooking soup\n",
    "    job_ads = soup.find_all('a', {'data-cy' : 'job-link'})  # scoping soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07c38e",
   "metadata": {},
   "source": [
    "1.2. Using the information obtained, perform a descriptive analysis on this data. You will need to formulate your own questions about what to find the data.\n",
    "\n",
    "When thinking about the website you would like to scrape and the information you can find from it, keep these points in mind:\n",
    "\n",
    "What kind of websites do I frequently visit?\n",
    "What type of data on these websites could be interesting to collect?\n",
    "What type of data would be interesting in your professional domain? (E.g. healthcare, finance, social media)\n",
    "If there is an API for the specific data you are planning to scrape, itâ€™s probably not worth trying to scrape it (E.g. Spotify API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9edc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575addb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fed66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1c1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a5543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84613cb0",
   "metadata": {},
   "source": [
    "1.3. Produce a report in the form of a clean notebook (or jupyter slides), with commented code and markdown cells for structuring and interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e9f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0533e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e4473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDBootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
